{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# installing necessary libraries\n",
    "!pip install -U sentence-transformers\n",
    "!pip install langchain-qdrant \n",
    "!pip install langchain \n",
    "!pip install langchain_community \n",
    "!pip install langchain_text_splitters \n",
    "!pip install langchain_huggingface"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "type of 'documents': <class 'list'>\n",
      "\n",
      "Number of  documents loader is getting: 1\n",
      "\n",
      "Number of chunks created by text splitter: 16\n",
      "\n",
      "\n",
      "type of 'found_docs': <class 'list'>\n",
      "\n",
      "Length of found_docs: 4\n",
      "\n",
      "Music and Audio Generation: Generative models can also produce music and audio. These models learn from existing audio datasets to create new compositions, sound effects, or even mimic specific styles or artists.\n",
      "\n",
      "Applications of Generative AI\n",
      "\n",
      "Creative Arts: Generative AI is transforming creative fields by enabling artists to explore new styles, generate novel artwork, and even co-create with AI systems. Tools like DeepArt and Artbreeder allow users to produce unique visual art by combining and altering existing images.\n",
      "\n",
      "Content Creation: In journalism, marketing, and entertainment, generative AI assists in creating articles, advertisements, and scripts. It can automate content generation processes, enhancing productivity and creativity.\n",
      "\n",
      "Medical Research: Generative models are used to design new molecules, simulate drug interactions, and generate synthetic medical data for research purposes. This can accelerate the discovery of new treatments and therapies.\n",
      "\n",
      "This is cosine score: 0.7431019486720722\n"
     ]
    }
   ],
>>>>>>> 42947fd (saved the notebook)
   "source": [
    "### loading langchain\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_qdrant import RetrievalMode\n",
    "\n",
    "### loading Embedder\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_qdrant import RetrievalMode\n",
    "\n",
    "\n",
    "## loading and splitting text documents\n",
    "loader = TextLoader(\"required_text.txt\")\n",
    "documents = loader.load()\n",
    "\n",
    "## printing information about documents \n",
    "print(f\"\\ntype of 'documents': {type(documents)}\")\n",
    "print(f\"\\nNumber of  documents loader is getting: {len(documents)}\")\n",
    "\n",
    "## splitting documents into chunks\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "## printing information about docs after splitting\n",
    "print(f\"\\nNumber of chunks created by text splitter: {len(docs)}\\n\")\n",
    "\n",
    "## Creating Embedder\n",
    "embedder = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "## qdrant in local disk memory ##########\n",
    "qdrant = QdrantVectorStore.from_documents(\n",
    "  docs,\n",
    "  embedding=embedder,\n",
    "  path=\"/home/dell/onboarding/local_qdrant\",\n",
    "  collection_name=\"my_documents\",\n",
    "  retrieval_mode=RetrievalMode.DENSE,\n",
    ")\n",
    "\n",
    "query = \"In what ways is generative AI being utilized in creative arts and content creation?\"\n",
    "found_docs = qdrant.similarity_search_with_score(query)\n",
    "\n",
    "## Printing info about 'found_docs'\n",
    "print(f\"\\ntype of 'found_docs': {type(found_docs)}\")\n",
    "print(f\"\\nLength of found_docs: {len(found_docs)}\\n\")\n",
    "\n",
    "\n",
    "document, score = found_docs[0]\n",
    "print(document.page_content)\n",
    "print(f\"\\nThis is cosine score: {score}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
